<!DOCTYPE html><!-- Author: Pranav Rajpurkar 2017--><html><head><meta charset="utf-8"><title>Countdown Regression</title><meta name="description" content="Countdown Regression: Sharp and Calibrated Survival Predictions."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><link rel="image_src" type="image/jpeg" href="/logo.jpg"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="icon" href="/favicon.ico" type="image/x-icon"><link href="/lib/bootstrap/css/bootstrap.min.css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Lato:400,600" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Muli:400,600" rel="stylesheet"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/simple-line-icons/css/simple-line-icons.css"><link href="/css/theme.css" rel="stylesheet"><link rel="stylesheet" type="text/css" href="/projects/chexnet/css/chexnet.css"><script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script><script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script><script src="/js/analytics.js"></script></head><body><nav class="navbar navbar-default navbar-fixed-top" id="mainNav"><div class="container"><!-- Brand and toggle get grouped for better mobile display--><div class="navbar-header"><a class="navbar-brand page-scroll" href="/">Stanford ML Group</a></div><!-- Collect the nav links, forms, and other content for toggling--></div></nav><section id="header"><div class="container"><div class="row"><div class="col-lg-12"><h1 id="page-title">Countdown Regression: Sharp and Calibrated Survival Predictions.</h1><h2>Anand Avati, Tony Duan, Kenneth Jung, Nigam H. Shah, Andrew Ng</h2></div></div></div></section><section><div class="container"><div class="row"><h2>A new machine learning approach to make forecasts of time to event.</h2><div class="col-lg-12"><p>Probabilistic forecasts of time to event (such as mortality) can be crucial in healthcare. A forecast is only useful if it is calibrated, meaning that predicted probabilities match real world frequencies (for example, among all the days that had a rain forecast of 80%, approximately 8 of 10 times it actually rained). If calibrated, a forecast's usefulness increases with its confidence (it is useless to always predict the long term average of rain, even though such a forecast would be well-calibrated). The field of meteorology has developed mathematical tools (such as the CRPS) to increase confidence in weather forecasts while maintaining calibration. We extend these tools to handle partial observations (a.k.a. censoring), thus making them suitable for use with time to event forecasting. We call this Survival-CRPS, and apply by training a Recurrent Neural Network (RNN) to predict time to mortality for millions of patients using their Electronic Health Record (EHR) data.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1806.08324">Read our paper</a></div></div></div></section><section class="gray"><div class="container"><div class="row"><h2>We introduce two techniques for more confident forecasts.</h2></div><div class="row"><div class="col-md-7"><p>Maximum Likelihood Estimation (MLE), the most common approach in machine learning, fails to work well for forecasting time to all-cause mortality with EHR data. This is because, in real world EHRs, the vast majority of the patients are alive. In low prevalence conditions, the mathematical properties of MLE tend to make survival forecasts that can be wildly unreasonable (for example, predicting the expected age-of-death to be many hundreds of years). Even though such forecasts are technically calibrated, this makes naive MLE based survival predictions practically unusable.</p><p>We present two independent techniques to improve the confidence of predictions in this scenario. First, we use our Survival-CRPS objective in place of MLE. Second, based on the fact that humans generally do not live past 120 years of age, we create Interval Censored variants of both Survival-CRPS and MLE. The two techniques independently, and jointly, improve the quality of survival predictions.</p><p>In this figure, we show examples of a patient's predicted distributions for age of death under different models. Repeated interactions (indicated by darker color) between the patient and the EHR yield more conÔ¨Ådent predictions of time of death.</p></div><div class="col-md-5"><img src="/projects/countdown-regression/img/cdr-sharpness-1.png"><img src="/projects/countdown-regression/img/cdr-sharpness-2.png"></div></div></div></section><section><div class="container"><div class="row"><h2>The Survival-CRPS score: graphical intuition.</h2></div><div class="row"><div class="col-md-8"><img src="/projects/countdown-regression/img/cdr-crps.png"></div><div class="col-md-4"><p>Our proposed Survival-CRPS score is best understood with a visualization of the Cumulative Distribution Function (CDF) of the forecast. As illustrated in the first figure, the original CRPS objective optimizes the forecast distribution to minimize the shaded area around <i>Y</i>, the actual outcome.</p></div></div><div class="row"><div class="col-md-12"><p>The Survival-CRPS is a generalization of this approach, as shown in the next two figures. It optimizes the forecast distribution to minimize the shaded regions only over those time periods where we are certain that the event (e.g death) has either not yet occured, or has already occurred (e.g the age at which the person turns 120 years).</p></div></div></div></section><section class="gray"><div class="container"><div class="row"><div class="h2">Sequential predictions over hospital interactions with Recurrent Neural Networks.</div></div><div class="row"><div class="col-md-5"><p>The RNN architecture is a natural fit for modeling data over time (such as patients making several visits to a hospital). We show that the model learns to make more confident predictions for the same patient given more history. This is illustrated in these pictures of six random patients, where the X-axis is the visit number of the patient, and in the Y-axis we plot the actual time to death (red line) and the corresponding forecasts (mean, upper and lower bounds of the 95% prediction interval). The sequential and monotonically decreasing set of time to event predictions in such an RNN model inspires the name <i>Countdown Regression</i>.</p><a class="btn btn-lg btn-default" href="https://arxiv.org/abs/1806.08324">Read our paper</a></div><div class="col-md-7"><img src="/projects/countdown-regression/img/cdr-countdown.png"></div></div></div></section><section class="bg-primary"><div class="container"><div class="row"><div class="col-md-12"><h3>If you have questions about our work,
contact us at:</h3><h4><code>avati@cs.stanford.edu</code></h4></div></div></div></section><footer><div class="container"><div class="row"><div class="col-md-12 text-center"><a href="/"><img src="/img/stanfordmlgrouplogo.svg"></a></div></div></div></footer><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/bootstrap/js/bootstrap.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script><script src="/js/theme.js"></script></body></html>